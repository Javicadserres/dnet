{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### RNN example\n",
    "\n",
    "In this notebook we will see an example of the RNN built in RNN.py. In this example we will be using the data person_names.txt to create new names."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "from pathlib import Path\r\n",
    "from dnet.layers import NLLLoss, RNN\r\n",
    "from dnet.optimizers import Adam\r\n",
    "from dnet.model import NNet"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "PATH = Path.cwd()\r\n",
    "PATH_DATA = PATH / 'data'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lets set the random.seed in order to generate always the same weights."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "np.random.seed(1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following functions are used to:\n",
    "\n",
    "1. **one_hot_encoding** In order to transform letters into inputs.\n",
    "\n",
    "2. **generate_names** Generate aleatory names."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def one_hot_encoding(input, size):\r\n",
    "    \"\"\"\r\n",
    "    Do one hot encoding for a given input and size.\r\n",
    "    \r\n",
    "    Parameters\r\n",
    "    ----------\r\n",
    "    input : list\r\n",
    "        list containing the numbers to make the \r\n",
    "        one hot encoding\r\n",
    "    size : int\r\n",
    "        Maximum size of the one hot encoding.\r\n",
    "        \r\n",
    "    Returns\r\n",
    "    -------\r\n",
    "    output : list\r\n",
    "        List with the one hot encoding arrays.\r\n",
    "    \"\"\"\r\n",
    "    output = []\r\n",
    "\r\n",
    "    for index, num in enumerate(input):\r\n",
    "        one_hot = np.zeros((size, 1))\r\n",
    "\r\n",
    "        if (num != None):\r\n",
    "            one_hot[num] = 1\r\n",
    "    \r\n",
    "        output.append(one_hot.tolist())\r\n",
    "\r\n",
    "    return np.array(output)\r\n",
    "\r\n",
    "\r\n",
    "def generate_names(index_to_character, model):\r\n",
    "    \"\"\"\r\n",
    "    Generates a random names with the pretrained RNN.\r\n",
    "    Parameters\r\n",
    "    ----------\r\n",
    "    index_to_character : dict\r\n",
    "        Dictionary that relates the indexes with the letters\r\n",
    "        to be used in order to create the name.\r\n",
    "    Returns\r\n",
    "    -------\r\n",
    "    name : list\r\n",
    "        List containing the final name predicted.\r\n",
    "    \"\"\"\r\n",
    "    letter = None\r\n",
    "    indexes = list(index_to_character.keys())\r\n",
    "\r\n",
    "    letter_x = np.zeros((model.layers[0].input_dim, 1))\r\n",
    "    name = []\r\n",
    "\r\n",
    "    # similar to forward propagation.\r\n",
    "    hidden = np.zeros((model.layers[0].hidden_dim , 1))\r\n",
    "\r\n",
    "    while letter != '\\n' and len(name)<15:\r\n",
    "        \r\n",
    "        hidden = model.layers[0].rnn_cell.forward(letter_x, hidden)\r\n",
    "        input_softmax = model.layers[0].lineal.forward(hidden)\r\n",
    "        y_pred = model.layers[0].softmax.forward(input_softmax)\r\n",
    "\r\n",
    "        index = np.random.choice(indexes, p=y_pred.ravel())\r\n",
    "        letter = index_to_character[index]\r\n",
    "\r\n",
    "        name.append(letter)\r\n",
    "\r\n",
    "        letter_x = np.zeros((model.layers[0].input_dim, 1))\r\n",
    "        letter_x[index] = 1\r\n",
    "\r\n",
    "    return \"\".join(name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data\n",
    "\n",
    "The data contains 18239 names."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "input_dim = 27\n",
    "output_dim = 27\n",
    "hidden_dim = 50\n",
    "\n",
    "# Load data with the names\n",
    "person_names = open(PATH_DATA / 'person_names.txt', 'r').read()\n",
    "person_names= person_names.lower()\n",
    "characters = list(set(person_names))\n",
    "\n",
    "character_to_index = {character:index for index,character in enumerate(sorted(characters))}\n",
    "index_to_character = {index:character for index,character in enumerate(sorted(characters))}\n",
    "\n",
    "with open(PATH_DATA / 'person_names.txt') as f:\n",
    "    person_names = f.readlines()\n",
    "\n",
    "person_names = [name.lower().strip() for name in person_names]\n",
    "np.random.shuffle(person_names)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Example of some of the names contained in person_names.txt"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "print(person_names[:5])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['alysse', 'phoebe', 'jabarri', 'alban', 'shaqwana']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Initialize the model\n",
    "model = NNet()\n",
    "# Create the model structure\n",
    "model.add(RNN(input_dim, output_dim, hidden_dim))\n",
    "\n",
    "loss = NLLLoss()\n",
    "optim = Adam()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Example of prediction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "for i in range(5):\n",
    "    name = generate_names(index_to_character, model)\n",
    "    print(name)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "buosmjz\n",
      "\n",
      "yxjepduggxxnwiz\n",
      "khazlsrraxynzgo\n",
      "jphvbaadkycqmie\n",
      "easqkscywqjjmyw\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Train the model\n",
    "costs = []\n",
    "num_epochs = 30000\n",
    "\n",
    "for epoch in range(num_epochs + 1):\n",
    "    # create the X inputs and Y labels\n",
    "    index = epoch % len(person_names)\n",
    "    X = [None] + [character_to_index[ch] for ch in person_names[index]] \n",
    "    Y = X[1:] + [character_to_index[\"\\n\"]]\n",
    "\n",
    "    # transform the input X and label Y into one hot enconding.\n",
    "    X = one_hot_encoding(X, input_dim)\n",
    "    Y = one_hot_encoding(Y, output_dim)\n",
    "\n",
    "    model.forward(X)\n",
    "    cost = model.loss(Y, loss)\n",
    "    model.backward()\n",
    "    model.optimize(optim)\n",
    "    \n",
    "    costs.append(cost)\n",
    "\n",
    "    if epoch % 10000 == 0:\n",
    "        print (\"Cost after iteration %epoch: %f\" %(epoch, cost))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cost after iteration 0.000000e+00poch: 0.832073\n",
      "Cost after iteration 1.000000e+04poch: 0.971043\n",
      "Cost after iteration 2.000000e+04poch: 0.562794\n",
      "Cost after iteration 3.000000e+04poch: 0.601051\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "for i in range(5):\n",
    "    name = generate_names(index_to_character, model)\n",
    "    print(name)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ketullanickei\n",
      "\n",
      "lorita\n",
      "\n",
      "ustal\n",
      "\n",
      "foshanda\n",
      "\n",
      "jicku\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Really well! It seems the model can create now new names."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mynet",
   "language": "python",
   "name": "mynet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}